{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(NLP)ASSIGNMENT_4.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pranay2627/NLP-Assignments/blob/main/(NLP)ASSIGNMENT_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axZrxiCsUGjx",
        "outputId": "efb959d2-7b3c-42ce-ce65-b65f868f61f6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.63.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "QeMpZmHlTNSW"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.util import pad_sequence\n",
        "from nltk.util import bigrams\n",
        "from nltk.util import ngrams\n",
        "from nltk.util import everygrams\n",
        "from nltk.lm.preprocessing import pad_both_ends\n",
        "from nltk.lm.preprocessing import flatten\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "import requests\n",
        "import io\n",
        "from nltk import word_tokenize, sent_tokenize \n",
        "from nltk.lm import MLE\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#   Basic N-gram Language Modelling"
      ],
      "metadata": {
        "id": "cMSpY2kxTS-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = [['where', 'are', 'you'], ['i', 'am', 'in', 'hyderabad', 'im', 'busy', 'at', 'work']]"
      ],
      "metadata": {
        "id": "8cCfR4HGTTxt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---Bigrams and trigrams generated---\")\n",
        "print(*list(bigrams(text[0])),sep=\"\\n\")\n",
        "print(*(list(ngrams(text[1], n=3))),sep=\"\\n\")\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vyazsXiUQzm",
        "outputId": "519ecef4-5619-4138-e66d-d8cdbad7d63a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Bigrams and trigrams generated---\n",
            "('where', 'are')\n",
            "('are', 'you')\n",
            "('i', 'am', 'in')\n",
            "('am', 'in', 'hyderabad')\n",
            "('in', 'hyderabad', 'im')\n",
            "('hyderabad', 'im', 'busy')\n",
            "('im', 'busy', 'at')\n",
            "('busy', 'at', 'work')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---Trigrams with padding symbols---\")\n",
        "padded_sent = list(pad_sequence(text[0], pad_left=True, left_pad_symbol=\"<s>\", pad_right=True, right_pad_symbol=\"</s>\", n=3))\n",
        "print(*list(ngrams(padded_sent, n=3)),sep=\"\\n\")\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUlqFiGNUTIR",
        "outputId": "61ae1204-0dfb-4d74-e6ce-90021c627687"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Trigrams with padding symbols---\n",
            "('<s>', '<s>', 'where')\n",
            "('<s>', 'where', 'are')\n",
            "('where', 'are', 'you')\n",
            "('are', 'you', '</s>')\n",
            "('you', '</s>', '</s>')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---Generated sample N-grams of max length = 2---\")\n",
        "padded_bigrams = list(pad_both_ends(text[0], n=2))\n",
        "print(*list(everygrams(padded_bigrams, max_len=2)),sep=\"\\n\")\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgJNiJwKUV5D",
        "outputId": "91cc58ed-afce-4078-c2ec-9136451c839e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Generated sample N-grams of max length = 2---\n",
            "('<s>',)\n",
            "('<s>', 'where')\n",
            "('where',)\n",
            "('where', 'are')\n",
            "('are',)\n",
            "('are', 'you')\n",
            "('you',)\n",
            "('you', '</s>')\n",
            "('</s>',)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---Flattened sentences with padding symbols---\")\n",
        "print(*list(flatten(pad_both_ends(sent, n=2) for sent in text)),sep=\"\\n\")\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9PjHBcWUYP4",
        "outputId": "be9b9779-6ace-4aee-f8a0-4d4d56a8f310"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Flattened sentences with padding symbols---\n",
            "<s>\n",
            "where\n",
            "are\n",
            "you\n",
            "</s>\n",
            "<s>\n",
            "i\n",
            "am\n",
            "in\n",
            "hyderabad\n",
            "im\n",
            "busy\n",
            "at\n",
            "work\n",
            "</s>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---Value of lazy iterators - train and vocab---\")\n",
        "training_ngrams, padded_sentences = padded_everygram_pipeline(2, text)\n",
        "print(\"Unigram and bigram training iterators:\")\n",
        "for ngramlize_sent in training_ngrams:\n",
        "    print(list(ngramlize_sent),sep=\"\\n\")\n",
        "    print()\n",
        "print('#############')\n",
        "print(\"Vocabulary iterator:\")\n",
        "print(list(padded_sentences))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0IRbuxYUbF4",
        "outputId": "8b5a3da8-8991-4ac0-fe94-a1d16b694fb5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Value of lazy iterators - train and vocab---\n",
            "Unigram and bigram training iterators:\n",
            "[('<s>',), ('<s>', 'where'), ('where',), ('where', 'are'), ('are',), ('are', 'you'), ('you',), ('you', '</s>'), ('</s>',)]\n",
            "\n",
            "[('<s>',), ('<s>', 'i'), ('i',), ('i', 'am'), ('am',), ('am', 'in'), ('in',), ('in', 'hyderabad'), ('hyderabad',), ('hyderabad', 'im'), ('im',), ('im', 'busy'), ('busy',), ('busy', 'at'), ('at',), ('at', 'work'), ('work',), ('work', '</s>'), ('</s>',)]\n",
            "\n",
            "#############\n",
            "Vocabulary iterator:\n",
            "['<s>', 'where', 'are', 'you', '</s>', '<s>', 'i', 'am', 'in', 'hyderabad', 'im', 'busy', 'at', 'work', '</s>']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#   Training an N-gram model"
      ],
      "metadata": {
        "id": "V-o6I-bZUdX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "url = \"https://gist.githubusercontent.com/alvations/53b01e4076573fea47c6057120bb017a/raw/b01ff96a5f76848450e648f35da6497ca9454e4a/language-never-random.txt\"\n",
        "text = requests.get(url).content.decode('utf8')\n",
        "with io.open('language-never-random.txt', 'w', encoding='utf8') as fout:\n",
        "    fout.write(text)\n",
        "tokenized_text = [list(map(str.lower, word_tokenize(sent))) for sent in sent_tokenize(text)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KC0ITaOUgq5",
        "outputId": "eae25ad7-7118-4b98-b1f7-3152cded1574"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---Preview of training corpus---\")\n",
        "print(print(text[:500]))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEUd0GxSU7lC",
        "outputId": "a757d9df-182c-460e-f35b-271f4d721f6d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Preview of training corpus---\n",
            "                       Language is never, ever, ever, random\n",
            "\n",
            "                                                               ADAM KILGARRIFF\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Abstract\n",
            "Language users never choose words randomly, and language is essentially\n",
            "non-random. Statistical hypothesis testing uses a null hypothesis, which\n",
            "posits randomness. Hence, when we look at linguistic phenomena in cor-\n",
            "pora, the null hypothesis will never be true. Moreover, where there is enough\n",
            "data, we shall (almost) always be able to establish \n",
            "None\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 3\n",
        "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)\n",
        "\n",
        "model = MLE(n)\n",
        "print(\"------ Initializing Model ------\")\n",
        "print(\"Length of vocabulary: \", len(model.vocab))\n",
        "print(\"------ Fitting Model ------\")\n",
        "model.fit(train_data, padded_sents)\n",
        "print(model.vocab)\n",
        "print(\"Length of vocabulary: \", len(model.vocab))\n",
        "print()\n",
        "\n",
        "print(\"---Preview of training corpus---\")\n",
        "print(model.vocab.lookup(tokenized_text[0]))\n",
        "print()\n",
        "\n",
        "print(\"---Model output with unseen data---\")\n",
        "print(model.vocab.lookup('language is never random lah .'.split()))\n",
        "print()\n",
        "\n",
        "# Using the N-gram language model\n",
        "\n",
        "print(\"---Trained model with count of N-grams---\")\n",
        "print(model.counts)\n",
        "print()\n",
        "\n",
        "print(\"count('language') = \", model.counts['language'])\n",
        "print(\"count('language is') = \", model.counts[['language']]['is'])\n",
        "print(\"count('language is never') = \", model.counts[['language', 'is']]['never'])\n",
        "print()\n",
        "\n",
        "print(\"P('language') = \", model.score('language'))\n",
        "print(\"P('is' | 'language') = \", model.score('is', 'language'.split()))\n",
        "print(\"P('never' | 'language is') = \", model.score('never', 'language is'.split()))\n",
        "print()\n",
        "\n",
        "print(\"P_log('language') = \", model.logscore('language'))\n",
        "print(\"P_log('is' | 'language') = \", model.logscore('is', 'language'.split()))\n",
        "print(\"P_log('never' | 'language is') = \", model.logscore('never', 'language is'.split()))\n",
        "print()\n",
        "\n",
        "# Sentence generation using N-gram model\n",
        "\n",
        "print(\"---Sentence generated using N-gram---\")\n",
        "print(model.generate(20, random_seed=7))\n",
        "print()\n",
        "\n",
        "print(model.score(\"<UNK>\")==model.score(\"lah\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD8HBvIiVMHK",
        "outputId": "62c814a6-a2c0-49cd-df7a-2d27b703bf86"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------ Initializing Model ------\n",
            "Length of vocabulary:  0\n",
            "------ Fitting Model ------\n",
            "<Vocabulary with cutoff=1 unk_label='<UNK>' and 1391 items>\n",
            "Length of vocabulary:  1391\n",
            "\n",
            "---Preview of training corpus---\n",
            "('language', 'is', 'never', ',', 'ever', ',', 'ever', ',', 'random', 'adam', 'kilgarriff', 'abstract', 'language', 'users', 'never', 'choose', 'words', 'randomly', ',', 'and', 'language', 'is', 'essentially', 'non-random', '.')\n",
            "\n",
            "---Model output with unseen data---\n",
            "('language', 'is', 'never', 'random', '<UNK>', '.')\n",
            "\n",
            "---Trained model with count of N-grams---\n",
            "<NgramCounter with 3 ngram orders and 19611 ngrams>\n",
            "\n",
            "count('language') =  25\n",
            "count('language is') =  11\n",
            "count('language is never') =  7\n",
            "\n",
            "P('language') =  0.003691671588895452\n",
            "P('is' | 'language') =  0.44\n",
            "P('never' | 'language is') =  0.6363636363636364\n",
            "\n",
            "P_log('language') =  -8.081510068120917\n",
            "P_log('is' | 'language') =  -1.1844245711374275\n",
            "P_log('never' | 'language is') =  -0.6520766965796932\n",
            "\n",
            "---Sentence generated using N-gram---\n",
            "['and', 'carroll', 'used', 'hypothesis', 'testing', 'has', 'been', 'used', ',', 'and', 'a', 'half', '.', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>']\n",
            "\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detokenize = TreebankWordDetokenizer().detokenize\n",
        "\n",
        "def generate_sent(model, num_words, random_seed=42):\n",
        "    \"\"\"\n",
        "    :param model: An ngram language model from `nltk.lm.model`.\n",
        "    :param num_words: Max no. of words to generate.\n",
        "    :param random_seed: Seed value for random.\n",
        "    \"\"\"\n",
        "    content = []\n",
        "    for token in model.generate(num_words, random_seed=random_seed):\n",
        "        if token == '<s>':\n",
        "            continue\n",
        "        if token == '</s>':\n",
        "            break\n",
        "        content.append(token)\n",
        "    return detokenize(content)\n",
        "\n",
        "print(\"---Generated sentence converted to human-readable form---\")\n",
        "print(generate_sent(model, 20, random_seed=7))\n",
        "print()\n",
        "\n",
        "print(model.vocab.lookup(tokenized_text[0]))"
      ],
      "metadata": {
        "id": "faH3GblkVVTa",
        "outputId": "4a90d092-fd40-4fa8-ee4e-25fc3a5ef9b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Generated sentence converted to human-readable form---\n",
            "and carroll used hypothesis testing has been used, and a half.\n",
            "\n",
            "('language', 'is', 'never', ',', 'ever', ',', 'ever', ',', 'random', 'adam', 'kilgarriff', 'abstract', 'language', 'users', 'never', 'choose', 'words', 'randomly', ',', 'and', 'language', 'is', 'essentially', 'non-random', '.')\n"
          ]
        }
      ]
    }
  ]
}